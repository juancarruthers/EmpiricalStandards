# Estudio de caso y Etnografía
<standard name="Case Study and Ethnography">

*"Una investigación empírica que estudia un fenómeno contemporáneo (el "caso")
 en profundidad y dentro de su contexto del mundo real, especialmente cuando los 
 límites entre el fenómeno y el contexto \[no están claros\]" (Yin 2017)*

## Aplicación

Este estándar se aplica a la investigación empírica que cumple las siguientes 
condiciones.

-   Presenta una descripción detallada de una instancia específica de un *fenómeno*
    en un *sitio*. El fenómeno puede ser, de manera práctica, cualquier cosa de interés
    (por ejemplo: Unix, métricas de cohesión, problemas de comunicación). El sitio puede ser
    una comunidad, una organización, un equipo, una persona, un proceso, una plataforma de
    internet, etc.
-   Incluye observación directa o indirecta (por ejemplo, entrevistas, 
    grupos focales) ---consulte la taxonomía de Lethbridge et al. (2005).
-   No es un informe de experiencia (cf. Perry et al. 2004) o una serie de 
    consultas superficiales en muchos sitios diferentes.

Un estudio de caso puede ser breve (por ejemplo, una semana de observación)
o longitudinal (si la observación excede el ritmo natural del sitio; por
ejemplo, observar un producto durante muchos lanzamientos). Para nuestros
propósitos, *el estudio de caso incluye la etnografía*.

Si la recopilación y el análisis de datos están intercalados, considere el 
**Estándar de Teoría Fundamentada**. Si el estudio menciona investigación
de acción o interviene en el contexto, considere el **Estándar de Investigación
Acción.** Si el estudio captura un gran conjunto de datos cuantitativos 
con un contexto limitado, considere el **Estándar de Ciencia de Datos Exploratoria**.

## Atributos Específicos
### Atributos Esenciales
<checklist name="Essential">

<intro>


<method>

- [ ]   Justifica la selección del caso o sitio que se estudió
- [ ]   Describe el sitio con gran detalle
- [ ]   Informa el tipo de estudio de caso<sup>[1](#myfootnote1)</sup>
- [ ]   Describe las fuentes de datos (p. ej., los datos demográficos y los roles laborales de los participantes)
- [ ]   Define la(s) unidad(es) de análisis

<results>

- [ ]   Presenta una cadena clara de evidencia desde las observaciones hasta los hallazgos

<discussion>


<other> 

</checklist>
    
### Atributos Deseables
<checklist name="Desirable">

- [ ]   Proporciona materiales complementarios como guías para entrevistas, esquemas de codificación, ejemplos de codificación, reglas de decisión o tablas de cadena de evidencia extendida
- [ ]   Triangula entre fuentes de datos, informantes o investigadores
- [ ]   Verifica las declaraciones de los entrevistados (por ejemplo, con observaciones directas o registros de archivo)
- [ ]   Utiliza la observación del participante (etnografía) o la observación directa (no etnografía) e integra claramente estas observaciones en los resultados<sup>[2](#myfootnote2)</sup> 
- [ ]   Valida los resultados mediante verificación de miembros, entrevistas dialógicas<sup>[3](#myfootnote3)</sup>, comentarios de profesionales no participantes o auditorías de codificación de investigación realizadas por asesores u otros investigadores
- [ ]   Describe eventos externos y otros factores que pueden haber afectado el caso o el sitio
- [ ]   Utiliza citas para *ilustrar* hallazgos<sup>[4](#myfootnote4)</sup>
- [ ]   O BIEN: evalúa una teoría a priori (o modelo, marco, taxonomía, etc.) utilizando codificación deductiva con un esquema de codificación a priori basado en la teoría anterior
        O: sintetiza los resultados en una teoría (o modelo, etc.) nueva, madura, completamente desarrollada y claramente articulada utilizando alguna forma de codificación inductiva (esquema de codificación generado a partir de datos)    
- [ ]   researchers reflect on their own possible biases
</checklist>

### Atributos Extraordinarios
<checklist name="Extraordinary">

- [ ]   Casos múltiples, profundos y completamente desarrollados con triangulación entre casos
- [ ]   Utiliza varios jueces y analiza la confiabilidad entre evaluadores (consulte el [Suplemento de IRR/IRA](https://github.com/acmsigsoft/EmpiricalStandards/blob/master/Supplements/InterRaterReliabilityAndAgreement.md))
- [ ]   Publicó un protocolo de estudio de caso de antemano y lo hizo accesible al público (consulte el [Suplemento de Reportes Registrados](https://github.com/acmsigsoft/EmpiricalStandards/blob/master/Supplements/RegisteredReports.md)) 
</checklist>

## Criterios de Calidad Generales

Los estudios de caso deben evaluarse utilizando criterios de validez cualitativa 
como credibilidad, multivocalidad, reflexividad, rigor
y transferibilidad  (ver **Glosario**). Los criterios de calidad cuantitativos como
la replicabilidad, la generalización y la objetividad no suelen 
aplicarse.

## Tipos de Estudios de Caso

No existe una forma estándar de realizar un estudio de caso. La investigación
de estudios de caso puede adoptar diferentes filosofías, en particular el 
(post-)positivismo (Lee 1989) y el interpretativismo/constructivismo (Walsham 1995),
y sirven para diferentes propósitos, que incluyen:

-   Un **estudio de caso descriptivo** describe---con gran detalle-- una instancia 
    particular de un fenómeno
-   Un **estudio de caso emancipatorio** identifica aspectos sociales, culturales o
    dominación política "que puede obstaculizar la capacidad humana" (Runeson y
    Host 2009), acorde con una postura epistemológica crítica
-   Un **estudio de caso evaluativo** evalúa preguntas de investigación a priori,
    proposiciones, hipótesis o artefactos tecnológicos
-   Un **estudio de caso explicativo** explica cómo o por qué un fenómeno
    Ocurrió, típicamente usando un proceso o teoría de varianza.
-   Un **estudio de caso exploratorio** explora un fenómeno particular para
    identificar nuevas preguntas, proposiciones o hipótesis
-   Un **estudio de caso histórico** se basa en datos de archivo, por ejemplo,
    repositorios de software
-   Un **estudio de caso revelador** examina un desconocido o 
    fenómeno inexplorado

## Antipatrones

-   Confiar en un enfoque único para la recopilación de datos (por ejemplo, entrevistas)
    sin corroboración ni triangulación
-   Simplificar y racionalizar en exceso fenómenos complejos; presentar cosas 
    complicadas y desordenadas como simples y limpias.

## Críticas Inválidas

-   No presenta datos cuantitativos; solo recopila un único tipo de
    datos.
-   Muestra de 1; hallazgos no generalizables. El objetivo de un estudio de caso 
    es estudiar una cosa en profundidad, no generalizar a una población. 
    Los estudios de casos deberían conducir a una generalización teórica; 
    es decir, conceptos transferibles en principio.
-   Falta de validez interna. La validez interna solo se aplica a los estudios de 
    casos explicativos que buscan establecer la causalidad.
-   Falta de reproducibilidad o "paquete de replicación"; Los datos no se divulgan 
    (los datos cualitativos suelen ser confidenciales).
-   Número de entrevistas de duración insuficiente. No existe un número mágico; 
    lo que importa es que haya suficientes datos para que los hallazgos sean 
    creíbles y la descripción sea profunda y rica.

## Lecturas Sugeridas

Line Dube and Guy Pare. Rigor in information systems positivist case
re-search: current practices, trends, and recommendations. 2003. *MIS
Quarterly.* 27, 4, 597–636. DOI: 10.2307/30036550

Shiva Ebneyamini, and Mohammad Reza Sadeghi Moghadam. 2018. Toward
Developing a Framework for Conducting Case Study Research.
*International Journal of Qualitative Methods.* 17, 1 (Dec. 2018)

Kilem Gwet. 2002. Inter-Rater Reliability: Dependency on Trait
Prevalence and Marginal Homogeneity. Statistical Methods for Inter-Rater
Reliability Assessment Series, 2 (May 2002), 9 pages.

Barbara Kitchenham, Lesley Pickard, and Shari Lawrence Pfleeger. 1995.
Case studies for method and tool evaluation. *IEEE software.* 12, 4
(1995), 52–62.

Timothy C. Lethbridge, Susan Elliott Sim, and Janice Singer. 2005.
Studying software engineers: Data collection techniques for software
field studies. *Empirical Software Engineering.* 10, 3 (2005), 311–341.

Mathew Miles, A Michael Huberman and Saldana Johnny. 2014. *Qualitative
data analysis: A methods sourcebook*. Sage.

Dewayne E. Perry, Susan Elliott Sim, and Steve M. Easterbrook. 2004.
Case Studies for Software Engineers, In *Proceedings 26th International
Conference on Software Engineering.* 28 May 2008, Edinburgh, UK,
736–738.

Per Runeson and Martin Höst. 2009. Guidelines for conducting and
reporting case study research in software engineering. *Empirical
Software Engineering*. 14, 2, Article 131.

Per Runeson, Martin Host, Austen Rainer, and Bjorn Regnell. 2012. *Case
study research in software engineering: Guidelines and examples.* John
Wiley & Sons.

Sarah J. Tracy. 2010. Qualitative Quality: Eight "Big-Tent" Criteria for
Excellent Qualitative Research. *Qualitative Inquiry*. 16, 10,
837–851.DOI:
[10.1177/1077800410383121](https://doi.org/10.1177/1077800410383121)

Geoff Walsham, 1995. Interpretive case studies in IS research: nature
and method. *European Journal of information systems.* 4,2, 74–81.

Robert K. Yin. 2017. *Case study research and applications: Design and
methods*. Sage publications.

## Ejemplares

Adam Alami, and Andrzej Wąsowski. 2019. Affiliated participation in open
source communities. In *2019 ACM/IEEE International Symposium on
Empirical Software Engineering and Measurement (ESEM)*. 1–11

Michael Felderer and Rudolf Ramler. 2016. Risk orientation in software
testing processes of small and medium enterprises: an exploratory and
comparative study. *Software Quality Journal*. 24, 3 (2016), 519–548.

Audris Mockus, Roy T. Fielding, and James D. Herbsleb. 2002. Two case
studies of open source software development: Apache and Mozilla. *ACM
Transactions on Software Engineering and Methodology (TOSEM).* 11, 3
(2002), 309–346.

Helen Sharp and Hugh Robinson. 2004. An ethnographic study of XP
practice. *Empirical Software Engineering.* 9, 4 (2004), 353–375.

Diomidis Spinellis and Paris C. Avgeriou. Evolution of the Unix System
Architecture: An Exploratory Case Study. *IEEE Transactions on Software
Engineering*. (2019).

Klaas-Jan Stol and Brian Fitzgerald. Two's company, three's a crowd: a
case study of crowdsourcing software development. In *Proceedings of the
36^th^ International Conference on Software Engineering*, 187–198, 2014.

---
<footnote><sup>[1](#myfootnote1)</sup>e.g. descriptive, emancipatory, evaluative, explanatory, exploratory, historical, revelatory</footnote><br> 
<footnote><sup>[2](#myfootnote2)</sup> Direct observation means watching research subjects without getting involved; participant observation means joining in with whatever participants are doing</footnote><br>
<footnote><sup>[3](#myfootnote3)</sup> L. Harvey. 2015. Beyond member-checking: A dialogic approach to the research interview, International Journal of Research & Method in Education, 38, 1, 23–38.</footnote><br>
<footnote><sup>[4](#myfootnote4)</sup> Las citas no deben ser *la única* representación de un hallazgo; cada hallazgo debe describirse independientemente de las citas de apoyo)</footnote><br> 
</standard>
