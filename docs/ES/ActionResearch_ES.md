# Action Research 
<standard name="Action Research">

*Investigación empírica que estudia cómo una intervención, como la 
introducción de un método o herramienta, afecta un contexto de la vida real.*

## Application 

Este estándar se aplica a la investigación empírica que cumple las 
siguientes condiciones.

-   Investiga un fenómeno principalmente social dentro de su contexto 
    organizacional de la vida real
-   Interviene en el contexto de la vida real (de lo contrario, 
    consulte el **Estándar de Estudio de Caso**)
-   El cambio y su observación son una parte integral de abordar la 
    pregunta de investigación y contribuir a la investigación.

Si la intervención altera principalmente los fenómenos sociales (por ejemplo, los
procesos de la organización, la cultura, la forma de trabajar o la dinámica de grupo),
utilice este estándar. Si la intervención es una nueva tecnología o técnica
(por ejemplo, una herramienta de prueba, un estándar de codificación, una gramática de modelado), especialmente
si carece de una dimensión social, considere el **Estándar de Investigación de Ingeniería**.
Si la investigación implica la creación de una tecnología y una intervención
organizacional con una dimensión social, considere ambos
estándares.

## Specific Attributes
### Essential Attributes
<checklist name="Essential">
    
<intro>


<method>
    
- [ ]   Justifica la selección de los sitios que fueron estudiados
- [ ]   Describe los sitios con gran detalle
- [ ]   Describe la relación entre el investigador y la organización de acogida<sup>[3](#myfootnote1)</sup>
- [ ]   Describe la(s) intervención(es) en detalle
- [ ]   Describe cómo se determinaron las intervenciones (p. ej., por parte de la gerencia, los investigadores o un proceso participativo/de codeterminación)
- [ ]   Explica cómo se evalúan las intervenciones<sup>[4](#myfootnote3)</sup>
- [ ]   Describe la dimensión longitudinal del diseño de la investigación (incluida la duración del estudio)
- [ ]   Describe las interacciones entre los investigadores y las organizaciones de acogida<sup>[1](#myfootnote1)</sup>
- [ ]   Explica los ciclos o fases de la investigación, si los hay, y su relación con las intervenciones<sup>[2](#myfootnote2)</sup>

<results>
    
- [ ]   Presenta una cadena clara de evidencia desde las observaciones hasta los hallazgos
- [ ]   Informa las reacciones de los participantes o partes interesadas a las intervenciones
    
<discussion>

- [ ]   Reporta las lecciones aprendidas por la organización
- [ ]   Los investigadores reflexionan sobre sus propios posibles sesgos

<other>

</checklist>
    
### Desirable Attributes
<checklist name="Desirable">
    
- [ ]   Proporciona materiales complementarios como guías para entrevistas, esquemas de codificación, ejemplos de codificación, reglas de decisión o tablas de cadena de evidencia extendida
- [ ]   Utiliza ampliamente citas directas
- [ ]   Valida los resultados mediante verificación de miembros, entrevistas dialógicas<sup>[5](#myfootnote1)</sup>, comentarios de profesionales no participantes o auditorías de investigación de codificación por asesores u otros investigadores
- [ ]   Hallazgos plausiblemente transferibles a otros contextos
- [ ]   Triangulación entre datos cuantitativos y cualitativos
</checklist>
    
### Extraordinary Attributes
<checklist name="Extraordinary">

- [ ]   Equipo de investigación con triangulación entre investigadores (para mitigar el sesgo de los investigadores)
</checklist>
     
## General Quality Criteria 

Los criterios de ejemplo incluyen reflexividad, credibilidad, resonancia, utilidad 
y transferibilidad (ver **Glosario**). Los criterios de calidad positivistas como 
la validez interna, la validez de constructo, la generalización y 
la fiabilidad no suelen aplicarse.

## Examples of Acceptable Deviations 

-   En un estudio sobre desviaciones de los estándares organizacionales, se omiten 
    descripciones detalladas de las circunstancias y las citas directas para 
    proteger a los participantes.
-   El artículo informa un resultado negativo de una intervención y, 
    por ejemplo, investiga por qué un determinado método no era aplicable.

## Antipatterns 

-   Forzar intervenciones que no sean aceptables para los participantes o la
    organización de acogida.
-   Perder la distancia y la imparcialidad profesionales; involucrarse demasiado 
    con la comunidad en estudio.
-   Vender en exceso una herramienta o método sin tener en cuenta los problemas,
    prácticas o valores de los participantes.
-   Evitar la evaluación sistemática; restar importancia a los problemas; reportar
    simplemente las opiniones de los participantes sobre la intervención.

## Invalid Criticisms 

-   Los hallazgos y los conocimientos no son válidos porque la investigación
    intervino en el contexto. Aunque la reflexividad es crucial,
    el objetivo de la investigación-acción es introducir un cambio y observar cómo
    reaccionan los participantes.
-   Esto es meramente una consultoría o un informe de experiencia. La observación
    y la reflexión sistemáticas no deben descartarse como consultoría o
    informes de experiencia. A la inversa, la consultoría o las experiencias no deben
    presentarse falsamente como investigación-acción.
-   Falta de datos cuantitativos; análisis causal; objetividad, validez interna,
    confiabilidad o generalización.
-   Muestra no representativa; falta de generalización; generalizar
    a partir de una organización.
-   Falta de replicabilidad o reproducibilidad; no publicar transcripciones.
-   Falta de grupos de control o protocolos experimentales. Un estudio de investigación-acción
    no es un experimento.

## Suggested Readings

Richard Baskerville and A. Trevor Wood-Harper. 1996. A critical
perspective on action research as a method for information systems
research.\" *Journal of information Technology* 11.3, 235–246.

Peter Checkland and Sue Holwell. 1998. Action Research: Its Nature and
Validity. *Systematic Practice and Action Research.* (Oct. 1997), 9–21.

Yvonne Dittrich. 2002. Doing Empirical Research on Software Development:
Finding a Path between Understanding, Intervention, and Method
Development. In *Social thinking---Software practice*. 243–262

Yvonne Dittrich, Kari Rönkkö, Jeanette Eriksson, Christina Hansson and
Olle Lindeberg. 2008. Cooperative method development. *Empirical
Software Engineering.* 13, 3, 231-260. DOI: 10.1007/s10664-007-9057-1

Kurt Lewin. 1947. Frontiers in Group Dynamics. *Human Relations* 1, 2
(1947), 143--153. DOI: 10.1177/001872674700100201

Lars Mathiassen. 1998. Reflective systems development. *Scandinavian
Journal of Information Systems* 10, 1 (1998), 67–118

Lars Mathiassen. 2002. Collaborative practice research. *Information,
Technology & People.* 15,4 (2002), 321–345

Lars Mathiassen, Mike Chiasson, and Matt Germonprez. 2012. Style
Composition in Action Research Publication. *MIS quarterly. JSTOR* 36, 2
(2012), 347-363

Miroslaw Staron. Action research in software engineering: Metrics'
research perspective. *International Conference on Current Trends in
Theory and Practice of Informatics.* (2019), 39-49

Maung K. Sein, Ola Henfridsson, Sandeep Purao, Matti Rossi and Rikard
Lindgren. 2011. Action design research. *MIS quarterly*. (2011), 37-56.
DOI: 10.2307/23043488

## Exemplars

Yvonne Dittrich, Kari Rönkkö, Jeanette Eriksson, Christina Hansson and
Olle Lindeberg. 2008. Cooperative method development. *Empirical
Software Engineering*. 13, 3 (Dec. 2007), 231-260. DOI:
10.1007/s10664-007-9057-1

Helle Damborg Frederiksen, Lars Mathiassen. 2005. Information-centric
assessment of software metrics practices. IEEE Transactions on
Engineering Eanagement. 52, 3 (2005), 350-362. DOI:
10.1109/TEM.2005.850737

Jakob Iversen and Lars Mathiassen. 2003. Cultivation and engineering of
a software metrics program. Information Systems Journal. 13, 1 (2006),
3--19

Jakob Iversen. 1998. Problem diagnosis software process improvement.
Larsen TJ, Levine L, DeGross JI (eds) Information systems: current
issues and future changes.

Martin Kalenda, Petr Hyna, Bruno Rossi. *Scaling agile in large
organizations: Practices, challenges, and success factors*. Journal of
Software: Evolution and Process. Wiley Online Library 30, 10 (Oct.
2018), 1954 pages.

Miroslaw Ochodek, Regina Hebig, Wilhem Meding, Gert Frost, Miroslaw
Staron. Recognizing lines of code violating company-specific coding
guidelines using machine learning. *Empirical Software Engineering*. 25,
1 (Jan. 2020), 220-65.

Kari Rönkkö, Brita Kilander, Mats Hellman, Yvonne Dittrich. 2004.
Personas is not applicable: local remedies interpreted in a wider
context. In *Proceedings of the eighth conference on Participatory
design: Artful integration: interweaving media, materials and
practices-Volume 1, Toronto, ON*, 112--120.

Thatiany Lima De Sousa, Elaine Venson, Rejane Maria da Costa Figueired,
Ricardo Ajax Kosloski, and Luiz Carlos Miyadaira Ribeiro. Using Scrum in
Outsourced Government projects: An Action Research. 2016. In *2016 49th
Hawaii International Conference on System Sciences (HICSS)*, January 5,
2016, 5447-5456.

Hataichanok Unphon, Yvonne Dittrich. 2008. Organisation matters: how the
organisation of software development influences the introduction of a
product line architecture. In *Proc. IASTED Int. Conf. on Software
Engineering*. 2008, 178-183.

---
<footnote><sup>[1](#myfootnote1)</sup> Es decir, ¿quién intervino y con qué parte de la organización?</footnote><br>
<footnote><sup>[2](#myfootnote2)</sup> Los proyectos de investigación-acción se estructuran en intervenciones que a menudo se describen como ciclos de investigación-acción, que a menudo se estructuran en distintas fases. Es una metodología flexible, donde los ciclos posteriores se basan en sus predecesores.</footnote><br>
<footnote><sup>[3](#myfootnote1)</sup> P.ej. financiación de proyectos, posibles conflictos de interés, relación profesional que conduzca al acceso.</footnote><br>
<footnote><sup>[4](#myfootnote3)</sup> Puede incluir evaluación cuantitativa además de evaluación cualitativa.</footnote><br>
<footnote><sup>[5](#myfootnote1)</sup> L. Harvey. 2015. Beyond member-checking: A dialogic approach to the research interview, International Journal of Research & Method in Education, 38, 1, 23–38.</footnote><br>
</standard>
