# Encuestas de Cuestionarios 
<standard name="Questionnaire Surveys">

*Un estudio en el que una muestra de encuestados responde una serie de preguntas (en su mayoría estructuradas), generalmente a través de un formulario computarizado o en papel.*

## Aplicación

Esta guía se aplica a estudios en los que:

- Una muestra de participantes responde preguntas predefinidas, en su mayoría cerradas (generalmente en línea o en papel)
- Los investigadores analizan sistemáticamente las respuestas de los participantes  


Este estándar no se aplica a los cuestionarios que comprenden predominantemente preguntas abiertas<sup>[1](#myfootnote1)</sup>, encuestas bibliográficas (consulte el **Estándar de Revisión Sistemática**), estudios longitudinales o de medidas repetidas (consulte el **Estándar de Estudios Longitudinales**), o los cuestionarios demográficos que normalmente se entregan a los participantes en experimentos controlados (consulte el **Estándar de Experimentos**).


## Atributos Específicos

### Atributos Esenciales
<checklist name="Essential">

<intro>

<method>

- [ ]   Identifica la población objetivo y define la estrategia de muestreo (consulte el [Suplemento de muestreo](https://github.com/acmsigsoft/EmpiricalStandards/blob/master/Supplements/Sampling.md))
- [ ]  Describe cómo se creó el instrumento de cuestionario
- [ ]  Describe cómo se seleccionaron o reclutaron los participantes (por ejemplo, marco de muestreo, publicidad, invitaciones, incentivos)
- [ ]  Descripción paso a paso, sistemática y reproducible de la recopilación y el análisis de datos
- [ ]  Describe cómo se gestionaron/supervisaron las respuestas, incluidas las acciones de contingencia para las no respuestas y los abandonos
- [ ]  O BIEN: mide los constructos usando (o adaptando) escalas validadas
       O: analiza la validez de constructo (incluida la validez de contenido, convergente, discriminante y predictiva) ex post<sup>[3](#myfootnote3)</sup>
- [ ]  Explica el manejo de los datos faltantes (por ejemplo, imputación, ajustes de ponderación, descarte)

<results>

- [ ]	Analiza las tasas de respuesta

<discussion>

- [ ]	Reconoce las amenazas de generalización; analiza cómo los encuestados pueden diferir de la población objetivo

<other>	
	
- [ ]	Proporciona el instrumento del cuestionario (como un apéndice o material complementario) 	
- [ ]	El diseño del cuestionario coincide con los objetivos de la investigación y la población objetivo<sup>[2](#myfootnote2)</sup>
	
</checklist>
     
### Atributos Deseables 	
<checklist name="Desirable">

- [ ]	Proporciona materiales complementarios que incluyen instrumentos, libros de códigos, scripts de análisis y conjuntos de datos
- [ ]	Caracteriza a la población objetivo, incluida la información demográfica (por ejemplo, cultura, conocimiento)
- [ ]	Tiene en cuenta los principios de la ética de la investigación (por ejemplo, consentimiento informado, riesgo de reidentificación)
- [ ]	Explica y justifica el diseño del instrumento y la elección de escalas (por ejemplo, por objetivos de investigación o por analogía con estudios similares)
- [ ]	Valida si los elementos, el diseño, la duración y la tecnología del instrumento son apropiados (por ejemplo, utilizando pilotos, prueba-reprueba o revisiones de expertos y no expertos)
- [ ]	Reporta cómo ha evolucionado el instrumento a través del proceso de validación (si es que lo ha hecho)
- [ ]	Analiza el sesgo de respuesta (cuantitativamente)
- [ ]   Incluye ítems para el control de atención en el cuestionario y excluye a los participantes que fallan uno o más de estos controles
- [ ]	Aplica técnicas para mejorar las tasas de respuesta (por ejemplo, incentivos, recordatorios, publicidad dirigida)
- [ ]	Analiza los posibles efectos de los incentivos (por ejemplo, sobre la voluntariedad, las tasas de respuesta, el sesgo de respuesta) si se utilizan
- [ ]	Describe la estratificación del análisis (si se utiliza un muestreo estratificado)
- [ ]	Define y estima el tamaño de los estratos de la población (si corresponde)
- [ ]	Distingue claramente los resultados basados en la evidencia de las interpretaciones y la especulación<sup>[4](#myfootnote4)</sup>
 </checklist>
     
### Atributos Extraordinarios	
<checklist name="Extraordinary">

- [ ]	Proporciona verificación de viabilidad de las técnicas de análisis de datos anticipadas
- [ ]	Informa sobre la validación de la escala en términos de dimensionalidad, confiabilidad y validez de las medidas
- [ ]   Diseño longitudinal en el que cada encuestado participa dos o más veces	
</checklist>

## Criterios Generales de Calidad

Los estudios de encuestas deben abordar criterios de calidad cuantitativos como **validez interna**, **validez de constructo**, **validez externa**, **confiabilidad** y **objetividad** (ver **Glosario**).

## Variaciones 

-   Las **Encuestas Descriptivas** proporcionan una descripción detallada de las propiedades de un fenómeno o una población.
-   Las **Encuestas Exploratorias** generan conocimientos, hipótesis o modelos para futuras investigaciones.
-   Las **Encuestas Confirmatorias** prueban proposiciones formales (por ejemplo, causales) para explicar un fenómeno.

## Ejemplos de Desviaciones Aceptables
- Omitir parte de un instrumento de cuestionario en los materiales complementarios debido a problemas de derechos de autor (en cuyo caso el documento debe citar la fuente de las preguntas)
- No describe el manejo de los abandonos o los datos faltantes porque no hubo ninguno.

## Críticas Inválidas

-   No informar la tasa de respuesta para las encuestas de suscripción pública abierta (es decir, encuestas abiertas al público anónimo para que todos los que tengan un enlace, que normalmente se difunden entre las redes sociales, puedan participar).
-   No publicar conjuntos de datos completos a pesar de que los datos son confidenciales.
-   Afirmar que el tamaño de la muestra es demasiado pequeño sin justificar por qué el tamaño de la muestra es insuficiente para responder a las preguntas de investigación.
-   Criticar la relevancia de una encuesta sobre la base de que las respuestas solo capturan las percepciones generales de la gente.
-   Los resultados se consideran controvertidos o poco sorprendentes.
-   Los resultados no concuerdan con la experiencia personal del revisor o con estudios previos.

## Lecturas Sugeridas

Don Dillman, Jolene Smyth, and Leah Christian. 2014. *Internet, phone,
mail, and mixed-mode surveys: the tailored design method.* John Wiley &
Sons.

Mark Kasunic. 2005. Designing an effective survey. Tech report
\#CMU/SEI-2005-GB-004, Carnegie-Mellon University, Pittsburgh, USA.

Jefferson Seide Molléri, Kai Petersen, and Emilia Mendes. 2020. An
empirically evaluated checklist for surveys in software engineering.*
Information and Software Technology*. 119.
	
Gary C. Moore, and Izak Benbasat. Development of an instrument to measure the perceptions of adopting an information technology innovation. *Information systems research* 2.3 (1991): 192-222.	

Paul Ralph and Ewan Tempero. 2018. Construct Validity in Software
Engineering Research and Software Metrics. In *Proceedings of the 22nd
International Conference on Evaluation and Assessment in Software
Engineering (EASE'18)*, 13–23. DOI:10.1145/3210459.3210461

Stefan Wagner, Daniel Mendez, Michael Felderer, Daniel Graziotin, Marcos
Kalinowski. 2020. Challenges in Survey Research. In: _Contemporary Empirical
Methods in Software Engineering_, Springer.
		
Marco Torchiano, Daniel Méndez, Guilherme Horta Travassos, and Rafael
Maiani de Mello. 2017. Lessons learnt in conducting survey research. In
*Proceedings of the 5th International Workshop on Conducting Empirical
Studies in Industry (CESI '17)*, 33–39. DOI:10.1109/CESI.2017.5

Torchiano Marco and Filippo Ricca. 2013. Six reasons for rejecting an
industrial survey paper. In *2013 1st International Workshop on
Conducting Empirical Studies in Industry (CESI)*, 21–26.

## Ejemplares 

Jingyue Li, Reidar Conradi, Odd Petter Slyngstad, Marco Torchiano,
Maurizio Morisio, and Christian Bunse. A State-of-the-Practice Survey on
Risk Management in Development with Off-The-Shelf Software Components.
In *IEEE Transactions on Software Engineering*. 34, 2 (2008), 271–286.

D. Méndez Fernández, Stefan Wagner, Marcos Kalinowski, Michael Felderer,
Priscilla Mafra, Antonio Vetrò, Tayana Conte et al. Naming the Pain in
Requirements Engineering: Contemporary Problems, Causes, and Effects in
Practice. In *Empirical software engineering*. 22, 5 (2016), 2298–2338.

Paul Ralph, Sebastian Baltes, Gianisa Adisaputri, Richard Torkar,
Vladimir Kovalenko, Marcos Kalinowski, et al. Pandemic Programming: How
COVID-19 affects software developers and how their organizations can
help. In *Empirical Software Engineering*, 25, 6, 2020, 4927–4961. DOI:
10.1007/s10664-020-09875-y

Stefan Wagner, Daniel Méndez Fernández, Michael Felderer, Antonio Vetrò,
Marcos Kalinowski, Roel Wieringa, et al. 2019. Status Quo in
Requirements Engineering: A Theory and a Global Family of Surveys. *ACM
Trans. Softw. Eng. Methodol.* 28, 2, Article 9 (April 2019), 48 pages.
DOI:10.1145/3306607

---
<footnote><sup>[1](#myfootnote1)</sup> Actualmente no existe un estándar para encuestas con cuestionarios predominantemente abiertos. Un ejemplo del que los lectores pueden sacar es: Daniel Graziotin, Fabian Fagerholm, Xiaofeng Wang, and Pekka Abrahamsson. 2018. "What happens when software developers are (un)happy." Journal of Systems and Software 140, 32-47.</footnote><br>
<footnote><sup>[2](#myfootnote2)</sup> Las preguntas se asignan a los objetivos de la investigación y su redacción y formato es apropiado para su audiencia.</footnote><br>
<footnote><sup>[3](#myfootnote3)</sup> Para consejos sobre el análisis de la validez de constructo, consulte Ralph, Paul, and Ewan Tempero. "Construct validity in software engineering research and software metrics." In Proceedings of the 22nd International Conference on Evaluation and Assessment in Software Engineering 2018, pp. 13-23</footnote><br>
<footnote><sup>[4](#myfootnote4)</sup> Por lo general, basta con separar los resultados y la discusión en diferentes secciones. Sin especulaciones en la sección de resultados.</footnote><br>
</standard>
