# Preguntas Frecuentes

### Donde puedo encontrar los estándares?

Puede encontrar los estándares, nuestro informe y presentación aquí: https://github.com/juancarruthers/EmpiricalStandards

### ¿Los estándares conducirán a trabajos de menor calidad, ya que los investigadores intentan hacer lo mínimo para obtener publicaciones?

Tenemos tres respuestas a esta pregunta: (1) Si todos hicieran lo mínimo para cumplir con los estándares, la calidad general de la investigación se dispararía. (2) Algunos investigadores pueden hacer lo mínimo, pero la academia es una tierra de sobresalientes. Para todos los que aspiran a un pase simple, probablemente hay dos o tres decididos a obtener un premio al mejor artículo. (3) Con el tiempo, podemos elevar el piso cambiando, haciendo que más atributos sean "esenciales".

### ¿Cómo afectan los estándares a los incentivos para producir una investigación no objetable pero de bajo impacto frente a una investigación controvertida pero potencialmente de alto impacto? ¿Priorizan el rigor sobre la relevancia, el interés y la importancia?

La revisión estructurada y basada en estándares facilitará la publicación de investigaciones controvertidas porque los revisores no podrán rechazar la investigación solo porque no estén de acuerdo con las conclusiones. La revisión estructurada y basada en estándares también facilitará la publicación de investigaciones relevantes porque evitará que los revisores apliquen incorrectamente las expectativas de experimentos controlados a enfoques in situ como la investigación de acción. 

Los investigadores no van a dejar de intentar realizar investigaciones significativas e impactantes debido a (1) criterios de promoción que no se limitan a los lugares de publicación; (2) la forma en que funcionan las subvenciones de investigación y (3) los propios egos y ambiciones de los académicos que los empujan a "poner un cambio en el universo". 

### ¿Cómo definen los estándares la utilidad y la importancia? ¿Cree que es posible definir tales estándares?

El estándar general simplemente pregunta a los revisores si el estudio contribuye a nuestro cuerpo colectivo de conocimiento. No hay calificación de utilidad o importancia.

Los revisores no son oráculos y no pueden predecir de manera confiable cómo se puede usar o afectar la investigación al mundo después de su publicación. Adoptamos la posición de que toda investigación rigurosa debe publicarse. Es hora de enfrentar la realidad de que la utilidad y la importancia solo pueden evaluarse años después de que se haya publicado el trabajo. Los revisores no son oráculos. 

### Incluso si el artículo sigue el estándar, para rechazar un artículo, un revisor puede simplemente decir que el artículo está mal escrito (tal vez porque está trabajando en el mismo tema). ¿A dónde pertenece eso? ¿Cómo se puede detectar ese comportamiento del revisor? ¿Se considera el lenguaje una medida de rechazo?

Incluso si el artículo sigue el estándar, para rechazar un artículo, un revisor puede simplemente decir que el artículo está mal escrito (tal vez porque está trabajando en el mismo tema). ¿A dónde pertenece eso? ¿Cómo se puede detectar ese comportamiento de revisor? ¿Se considera el lenguaje una medida de rechazo?

El estándar general tiene una prueba simple para la calidad de la escritura: “ningún problema gramatical no obstaculiza sustancialmente la comprensión”. Lo que importa es si el lector puede entender el artículo. Si la escritura es lo suficientemente buena como para ser entendida, es lo suficientemente buena como para publicarla. Si el lector no puede entender el artículo, entonces no está listo para publicar. La revisión estructurada significa que al menos la mayoría de los revisores tendrían que sentir que el artículo no era comprensible para llevar a una decisión de rechazo. 

### Las reseñas no se tratan solo de aceptación, sino también de retroalimentación. Una diferencia entre conferencias buenas y malas (además de la tasa de aceptación) es la calidad de los comentarios y las sugerencias de mejora. ¿Esta propuesta no convierte la retroalimentación en una cuestión opcional?  

La “revisión del desarrollo” es un arma de doble filo. Algunos comentarios de los revisores son útiles. Mucho es destructivo, abusivo y de hecho incorrecto. El objetivo de los estándares es dejar claras las expectativas ANTES de que se realice la investigación y se envíe el artículo, en lugar de revelarlas después, cuando sea demasiado tarde para hacer el estudio de otra manera.

La iniciativa de estándares busca reemplazar la retroalimentación no estructurada y no autorizada con retroalimentación estructurada basada en el consenso de la comunidad. Las revisiones seguirán recibiendo comentarios como "aclarar la pregunta de investigación" o "proporcionar más detalles sobre la recopilación de datos, incluidos X, Y y Z". Pero los estándares evitarán el abuso ("el autor debe considerar una carrera diferente"), la crítica interparadigmática ("A pesar de ser un artículo cualitativo, necesita más números") y la retroalimentación incorrecta ("Esta RSL no es sistemática porque no incluye todos los trabajos relevantes ”). Todos estos son ejemplos reales. 

Si los lugares optan por incluir comentarios de los revisores de forma extensa, eso depende de ellos, pero lo desaconsejamos, porque muchos revisores han demostrado una y otra vez que no se puede confiar en ellos para que brinden comentarios correctos, imparciales y abiertos.

### ¿Los estándares apoyan el ranking de los artículos que de otra manera cumplen con los estándares?
    
Los estándares permiten un ranking aproximado de los artículos en función del número de atributos deseables y extraordinarios. No estamos seguros de que ranquear los artículos sea una buena idea.

### ¿Cómo funcionaría esto con conferencias y revistas que tienen menos espacios para presentar que presentaciones?

El número limitado de "espacios" en las revistas es un efecto secundario de la idiotez de imprimir artículos en árbol muerto, y no deberíamos aceptar tales límites. Además, utilizar la tasa de aceptación como medida de la calidad de la conferencia es inválido, indefendible y anti-científico. La competencia es un anatema para la ciencia. 

Si hay más trabajos aceptados que espacios para hablar, tal vez deberíamos dejar que los asistentes voten por los trabajos más emocionantes (que obtienen espacios para hablar) y el resto se presenta como póster pero aún se publica como artículos completos en las actas. Esa es solo una idea. El punto es que debemos repensar fundamentalmente la forma en que llevamos a cabo las conferencias, deshacernos de toda la competencia contraproducente y publicar toda la investigación legítima. 

### ¿Podría este tipo de lista de verificación de los criterios de revisión en combinación con los límites de página exigidos para los PDF conducir a más rechazos al final, ya que no es posible abordar todos los puntos en las pautas y los revisores rechazan, por ejemplo, si no encuentran ninguna información en un criterio particular?

Los límites de páginas arbitrarios son estúpidos por la misma razón que los espacios en las revistas. Dicho esto, los estándares deberían permitirnos escribir artículos más breves y concisos porque no es necesario explicar tanto cuando las cosas están más estandarizadas y no es necesario incluir tanto texto defensivo para evitar una multitud de críticas irrelevantes. Si lee detenidamente los estándares, es todo lo que incluiría de todos modos. Los estándares también alientan a los autores a presentar detalles adicionales en materiales complementarios, apéndices, paquetes de replicación, etc. Si recibimos muchos informes sobre no poder incluir todos los detalles necesarios en un tipo específico de artículo, revisaremos el estándar y haremos que los criterios sean más concisos. 

### ¿Cómo puede este método mantenerse al día con los métodos en evolución y los estándares cambiantes?

Los estándares se alojarán en un sistema de control de versiones (GitHub) con un rastreador de problemas y mantenedores que mejorarán constantemente los estándares en función de la retroalimentación.

### ¿Los estándares harán que los artículos sean aún menos comprensibles para los no investigadores (es decir, la gente de la industria)?

Tratar de que los profesionales lean estudios primarios individuales probablemente no sea realista e incluso podría ser perjudicial. En la medida en que los profesionales lean la investigación, deben leer revisiones sistemáticas y artículos similares que sinteticen los cuerpos de trabajo en recomendaciones prácticas. Por lo tanto, el estándar RSL incluye el criterio esencial: "presenta conclusiones o recomendaciones para profesionales / no especialistas". 

### Las conferencias generales como ICSE no solo aceptan estudios empíricos. Si solo tuviéramos estándares detallados para los estudios empíricos, ¿sería más difícil publicar investigaciones empíricas que investigaciones no empíricas? 

No creemos que sea posible dificultar más la publicación de investigaciones no empíricas en ICSE. Hace años, el método dominante para evaluar una nueva herramienta de software era simplemente afirmar que funcionaba "porque yo lo dije". La Ingeniería de Software reaccionó exageradamente, y ahora publicar un estudio no empírico en ICSE es prácticamente imposible. Parece muy poco probable que los estándares empíricos, tal como están escritos actualmente, puedan hacer que los principales lugares de Ingeniería de Software cambien completamente de sentido y se vuelvan sesgados en contra de la investigación empírica. Por el contrario, necesitamos crear un espacio para publicar estudios académicos no empíricos de alta calidad, como exploraciones conceptuales de cuestiones metodológicas y filosóficas. Quizás ICSE debería tener una pista separada para la investigación no empírica, fundamental y conceptual.  

### ¿Los estándares harán que sea más difícil publicar un estudio usando una metodología para la cual existe un estándar que un estudio con un método que no tiene un estándar?

No. Los estándares facilitan la publicación porque evitan que los revisores inventen criterios inesperados.

### Algunos artículos mezclan una contribución teórica (digamos un nuevo algoritmo) con una pequeña evaluación empírica. ¿Deberían evaluarse con los mismos estándares?

El Estándar de Investigación en Ingeniería (Alias Diseño Científico) cubre dichos artículos. 

### ¿Cuál es la perspectiva actual de que los foros de Ingeniería del Software adopten estos estándares? ¿Alguno de los foros ya ha utilizado alguno de estos estándares?

EASE 2021 y ESEM 2021 han adoptado los estándares. JSS está intentando descubrir cómo integrar los estándares en su director editorial. Actualmente estamos enfocados en terminar los estándares en progreso y construir el sistema que genera los formularios de revisión. Luego, comenzaremos a trabajar más con revistas y conferencias. Dicho esto, cualquier revisor puede utilizar voluntariamente los estándares como guía, y cualquier lugar que desee experimentar con los estándares puede hacerlo. Una mayor adopción es inevitable: los estándares son tan abrumadoramente útiles que todas las principales revistas y conferencias eventualmente los adoptarán de alguna manera. 

### ¿Cómo se aseguró de que sus criterios estuvieran bien estructurados para cada tema y campo?

Los criterios se dividen por "metodología" en lugar de "tema y campo". Nos aseguramos de que los criterios sean razonables y estén bien estructurados mediante la contratación de expertos en cada método para redactar su estándar, revisando cada estándar en varias rondas y editando todos los estándares juntos para garantizar la coherencia. Por supuesto, los estándares siguen siendo imperfectos; de ahí el enfoque en la evolución y el mantenimiento continuos.   

### ¿Por qué los "elementos esenciales" son simplemente booleanos? ¿No es demasiado simplista?

Las preguntas de sí / no conducirán a la mayor confiabilidad entre evaluadores y a la menor confusión. Sin embargo, los criterios no son simplistas. Por ejemplo, el criterio general "la metodología es apropiada (no necesariamente óptima) para el propósito o las preguntas declaradas" todavía requiere que un ser humano inteligente piense en la relación entre el propósito y el método del artículo y decida si encajan. 

### ¿Cuándo necesitarán los revisores emitir un juicio experto / juicio subjetivo?

Cada vez que un revisor verifica un criterio, realiza un juicio subjetivo. Es fundamentalmente imposible hacer que la revisión por pares sea objetiva o algorítmica. El propósito de las normas es dirigir el juicio de expertos (como los precedentes legales), no reemplazarlo.  

### ¿Las decisiones finales son generadas solo por la lista de verificación ponderada? ¿Qué pasa con preguntas como si el conjunto de datos es lo suficientemente grande o no?

No hay ponderación de la lista de verificación. Todos los artículos que cumplen con los criterios esenciales son publicables. Los foros pueden crear reglas de decisión más complejas, pero no hay nada como el promedio ponderado. Hay varios criterios relacionados con suficiente poder estadístico (para trabajo cuantitativo) o saturación (para trabajo cualitativo). 

### Parece que también hay diversidad en el software que se envía con los artículos. ¿Qué lecciones cree que se pueden trasplantar de las revisiones de artículos a las revisiones de códigos?

Esa es una muy buena pregunta y estaremos encantados de facilitar la investigación sobre este tema. Estamos trabajando en un estándar para la evaluación de artefactos, incluida la evaluación del software enviado con un documento o en una pista de artefactos. 

### ¿Ve la posibilidad de un "pirateo estándar" en el futuro? Ya que, en cierto modo, es un poco como un "examen a libro abierto" para las presentaciones de trabajos.

¡Solo podemos esperar! Los estándares están llenos de mejores prácticas de investigación; por lo tanto, intentar piratear un estudio / artículo para maximizar las posibilidades de aceptación cumpliendo con los estándares mejorará drásticamente la calidad de la investigación. ¡Se supone que el examen es a libro abierto! Los autores deben saber exactamente lo que buscan los revisores. Mantener los criterios de revisión en secreto es una locura.  

### ¿Qué tipo de criterios hay en el estándar para ________?

Puede ver todos los criterios en: https://github.com/juancarruthers/EmpiricalStandards

### ¿Existe todavía alguna evidencia de que tales pautas *ayuden* en todas las formas mencionadas?

La efectividad de las listas de verificación sobre la actividad profesional está bien establecida, por eso los cirujanos usan listas de verificación en los quirófanos. Además, la idea de pasar a criterios binarios más estructurados y atomísticos para mejorar la confiabilidad entre evaluadores está bien establecida. 

### ¿Se han probado empíricamente los estándares? Por ejemplo, ¿ha realizado una "prueba retrospectiva" de los estándares con documentos históricos aceptados y rechazados, y ha comparado los resultados con alguna noción real de la calidad del artículo?

Todavía no porque solo han existido durante unos meses y todo nuestro tiempo se consume actualmente tratando de terminar los estándares que aún están en progreso. Si alguien está interesado en organizar pruebas empíricas de los estándares, estaremos encantados de facilitarlo. Póngase en contacto con nosotros. 

### Mencionaste que el informe de experiencia no es un estudio empírico. ¿Esto es general, o puede haber estudios en los que el informe realmente utilice análisis de datos y métodos implícitamente empíricos?

Debería haber dicho que, al menos por ahora, los informes de experiencia están fuera del alcance de los estándares empíricos, a menos que recopilen y analicen datos de forma sistemática, en cuyo caso podrían contarse como estudios de caso. La línea entre "informe de experiencia" y "estudio de caso" es un poco borrosa.

### ¿Por qué los estándares no están organizados por sección? Por ejemplo: "Introducción, Antecedentes, Método ... Conclusión"

No queremos microgestionar la organización del artículo. Queremos que los revisores se centren en la esencia de cada artículo y el rigor del estudio que presenta.

### ¿Existe alguna evidencia de un sistema de revisión por pares que no funcione?

Oh wow, ¿por dónde empezamos? Prácticamente todos los estudios empíricos de revisión por pares han concluido que está totalmente roto. La revisión por pares es poco confiable, ineficiente, sexista, racista y está sesgada en contra de las nuevas ideas y los hablantes de inglés no nativos. Para obtener una descripción general, consulte: 

Ann Weller, 2001. Editorial peer review: Its strengths and weaknesses. _Information Today, Inc._

y
 
P. Ralph (2016) Practical suggestions for improving scholarly peer review quality and reducing cycle times. _Communications of the Association for Information Systems_, (38), Article 13.

### ¿No surgen muchos problemas con la revisión por pares debido a la falta de compensación monetaria de los editores a los revisores? Las buenas revisiones técnicas exigen mucho tiempo y los revisores deberían recibir un pago por ello.

Apoyamos al 100% las iniciativas para compensar económicamente a los revisores por su trabajo.

### ¿Qué hay del factor gente? Todos sabemos que hay tantas críticas malas incluso en las mejores conferencias. Cuando alguien envía incluso una crítica obviamente mala, no le sucede absolutamente nada al revisor. Los directivos del comité del programa no realizan ningún tipo de control de calidad, simplemente dejan pasar las malas críticas. No hay ninguna penalización por proporcionar una reseña de mala calidad.

Los revisores son voluntarios, por lo que los editores y directores de programas se sienten incapaces de disciplinarlos cuando se portan mal. Los editores asociados y los meta-revisores a menudo no están dispuestos a estar en desacuerdo con los revisores porque no quieren hacerse enemigos. Los revisores que más necesitan corrección suelen estar más a la defensiva, por lo que cuando algún tipo de editor los corrige, tienden a quejarse, y luego el editor es etiquetado como alguien que menosprecia a otros revisores y se excluye de futuras funciones editoriales. No podemos arreglar una organización de voluntarios aplicando autoridad, no importa cuán legítima sea. En su lugar, rediseñamos el sistema de revisión para que, en primer lugar, evite activamente las malas revisiones. No podemos obligar físicamente a los revisores a leer con más atención, pero podemos evitar que escriban un ensayo incompetente reduciendo el texto libre y aumentando la estructura.  

### ¿Cómo pueden ayudar los estándares empíricos a los revisores malintencionados?

Un proceso de revisión estructurado y basado en estándares es mejor para identificar revisores problemáticos. Los revisores problemáticos tendrán niveles más bajos de acuerdo con otros revisores. El acuerdo es fácil de medir con una revisión estructurada, por lo que el sistema comenzará a identificar a los revisores problemáticos.

Además, el actual sistema roto permite que un revisor negativo anule a dos o tres revisores positivos, lo que lleva al rechazo de un artículo. Los estándares no funcionan de esa manera. Si dos revisores no están de acuerdo con un criterio (como si un experimento tiene o no un grupo de control), la pregunta se eleva a un tercer revisor o editor. No hay una discusión larga, solo pide otra opinión. Todos los desacuerdos deben resolverse de una forma u otra, y la decisión se basa en las reglas de decisión del foro, no en las creencias de ningún revisor individual. Ya no hay más que decir simplemente "uno de los revisores está descontento". 

El movimiento de ICSE hacia la toma de decisiones por consenso a través de la discusión del revisor suena bien, pero no lo es. Los desacuerdos entre los revisores se vuelven desagradables rápidamente, por lo que todos caminan en cáscaras de huevo, y eso significa que el crítico más ruidoso y beligerante a menudo se sale con la suya. Los revisores negativos critican a los revisores positivos con más frecuencia que al revés, lo que reduce las tasas de aceptación. Los criterios de revisión detallados y específicos nos permiten volver a la votación, que es más justa y eficiente. 

### Premisa: esta iniciativa suena valiosa. Duda: un "estándar" es inflexible por definición, por lo tanto, arriesgado. Por ejemplo: la selección aleatoria de participantes no siempre (!) es algo bueno; ¿cómo evitar juzgar las obras sobre la norma y no sobre la obra específica real?

Nuestro actual sistema de revisión por pares es arriesgado. Se corre el riesgo de rechazar una investigación sólida debido a revisores sesgados, privar de sus derechos a los buenos académicos para que renuncien y aceptar trabajos bien escritos pero metodológicamente deficientes. Nuestro sistema actual crea división e inequidad, los académicos son rechazados por becas bien merecidas, tenencia y promoción y los artículos se envían a cinco foros diferentes antes de ser publicados. La revisión basada en estándares mitiga estos riesgos. 

Los estándares no dicen cosas como "los participantes deben seleccionarse al azar". Los estándares dicen cosas como "el documento debe explicar la estrategia de muestreo y por qué es apropiado para el estudio".

### ¿Los estándares discriminan a los investigadores que inventan nuevos métodos o aplican métodos atípicos? ¿Cree que el marco general de estándares empíricos se trasladaría a otras disciplinas? ¿Tiene el marco la flexibilidad para evaluar la investigación interdisciplinaria o la investigación que involucre métodos innovadores? 

El estándar general establece explícitamente que los estudios nuevos o atípicos no deben rechazarse solo porque no existe un estándar específico de método aplicable. El estándar general debería seguir aplicándose a métodos nuevos e innovadores. Dice cosas como "Analiza la importancia, las implicaciones y las limitaciones (amenazas a la validez) del estudio". Es difícil imaginar un método de investigación nuevo e innovador en el que los artículos ya no discutan sus implicaciones y limitaciones. Sin embargo, los estándares también enfatizan que las desviaciones justificadas son bienvenidas. Siempre que un revisor sienta que un criterio no se satisface, el sistema le preguntará explícitamente si se ofreció una justificación razonable. 

El estándar general fue escrito para la investigación en Ingeniería de Software. Debería aplicarse a casi todas las investigaciones empíricas en Ingeniería de Software. Podría aplicarse a otros campos con algunos ajustes.

Los otros estándares son específicos del método. El estándar de encuesta de cuestionario es para encuestas de cuestionario. No debe usarse para evaluar un tipo diferente de estudio, como un grupo focal. Es probable que algunos de los estándares específicos del método se puedan adaptar para otras áreas de investigación, y las personas de otras comunidades pueden intentarlo.

### ¿Cómo lo hacen otras disciplinas? ¿Son menos diversos que en la Ingeniería de Software? ¿Tienen estándares empíricos que funcionen y produzcan las ventajas discutidas?

Todas las comunidades intentan escribir criterios para juzgar el trabajo científico (como las pautas de los revisores) y algunas comunidades científicas (por ejemplo, SIGPLAN) han intentado escribir cosas como "estándares empíricos". Estos anteriores han tenido algunos éxitos a pesar de sufrir varios problemas que incluyen: (1) falta de detalles; (2) tratar de obligar a todos a adoptar una visión de la ciencia demasiado limitada y obsoleta (como el positivismo lógico); (3) no distinguir entre metodologías diferentes. Nuestros estándares son mucho más detallados y completos, sin imponer una posición epistemológica u ontológica singular. Logramos esto al tener diferentes enfoques para diferentes estándares. El alto nivel de diversidad metodológica de nuestra comunidad requiere y evita este enfoque de estándares múltiples. 

### Sería útil cubrir también el método X. ¿Están planeando hacerlo?

Si desea que se cree un estándar para un método determinado (por ejemplo, grupos focales), presente un issue en el repositorio de GitHub. Puede sugerir personas que podrían redactar dicho estándar, incluido usted mismo, y el contenido que podría incluirse. Tenemos que equilibrar la necesidad de una guía específica para un método con la complejidad de tener demasiados estándares, pero si mucha gente quiere un estándar para un método determinado y alguien está dispuesto a escribir un primer borrador, lo incluiremos.  

### Este material debe utilizarse para formar la próxima generación de ingenieros de software. ¿Algún plan para integrar esto en los planes de estudio?

Los estándares claramente tienen mucha utilidad pedagógica para la enseñanza de métodos de investigación. Paul los está usando en su curso de métodos cuantitativos avanzados en el invierno de 2021. No estamos seguros de si son apropiados para estudiantes universitarios, pero si alguien quiere probar, puede hacerlo y nos encantaría conocer sus experiencias.
